# CI Agent

Competitive Intelligence Agent built around a meta-language for CI tasks, a Streamlit UI, simple Markdown for exportable reports,and reproducible dependency management with `uv`.

Important change: this codebase has deprecated active use of Meta/OpenAI provider integrations and now prefers Google Generative (Gemini) integrations via the `google-generativeai` SDK / ADK where available. OpenAI-related code paths remain as legacy fallbacks in some places but are no longer the recommended or default runtime path.

## Features

1. Google Generative (Gemini) / ADK integration (preferred) for generation and agent workflows. The repo supports the `google-generativeai` SDK and uses `GenerativeModel.generate_content` where available. BYOK.
2. (Legacy) OpenAI Agents SDK integration — kept for backward compatibility but deprecated. New development should use the Google path.
2. Streamlit graphical interface to invoke agent commands.
3. uv for fast, reproducible dependency resolution and virtual environments.
4. ruff for lint and format checks in local and CI workflows.
5. Dockerfile with multi-stage build and non-root runtime.
6. GitHub Actions workflow for linting, testing, caching, and image publishing to GHCR.

## Repository Structure

```
ci-agent/
  pyproject.toml
  uv.lock                 # optional; generated by uv and committed for deterministic builds
  .ruff.toml
  .dockerignore
  Dockerfile
  Makefile
  README.md
  src/
    ci_agent/
      __init__.py
      agent.py
      cli.py
      streamlit_app.py
  tests/
    test_ci_agent.py
  .github/
    workflows/
      ci.yml
```

## Prerequisites

- Python 3.11 or later
- `uv` installed locally (we use `uv` to manage the project virtualenv and dependencies)
- Podman (recommended for local container runs) or Docker (used by CI)
- A Google Generative (Gemini) API key to enable the preferred runtime path. Add it locally to a `.env` file as `GOOGLE_API_KEY=your_key_here` and do NOT commit that file into the repo. If you have an ADK/enterprise setup, follow your org's auth guidance.
- (Optional/legacy) An OpenAI-compatible key may still be present to exercise fallback code paths, but OpenAI usage is deprecated and not recommended for new runs.

Important: This repository manages all project dependencies with `uv`. Prefer `uv` commands or the provided `make` targets so the `uv.lock` file remains authoritative and builds are reproducible. Avoid direct `pip install` for project dependencies unless explicitly instructed.

## Quickstart (Local)

1. Create environment and sync dependencies.

Environment note: the app reads `GOOGLE_API_KEY` from a local `.env` (via `python-dotenv`) if present. Do not commit your `.env` file or your API keys to source control.

Recommended (creates `.venv` and syncs deps via `uv`):

```bash
make setup
```

If you want to install only the Google/Gemini SDK into the uv-managed environment (the `setup` target already installs all extras), you can run:

Unix/macOS:

```bash
UV_PROJECT_ENVIRONMENT=.venv uv sync --all-extras --dev
UV_PROJECT_ENVIRONMENT=.venv uv pip install google-generativeai
```

Windows (PowerShell):

```powershell
powershell -ExecutionPolicy Bypass -Command "$env:UV_PROJECT_ENVIRONMENT='.venv'; uv sync --all-extras --dev"
powershell -ExecutionPolicy Bypass -Command "$env:UV_PROJECT_ENVIRONMENT='.venv'; uv pip install google-generativeai"
```

Alternatively, if you prefer to install the optional extras via pip as a fallback (not recommended for regular development), you can run:

```bash
python -m pip install '.[google]'
```

2. Lint and test.

```bash
make lint
make test
```

3. Run the Streamlit UI.

```bash
make run
# Open http://localhost:8501
```

## Command-line Usage

The CLI wraps the agent and builds a meta-language call based on arguments.

```bash
python -m ci_agent.cli --cmd CI_landscape --entities "Company A" "Company B" "Company C" --format markdown --urls https://example1.com https://example2.com https://example3.com
```

Adding URLs with the `--urls` flag provides specific sources for the agent to research, significantly improving the accuracy and factual basis of the analysis. The agent will primarily use information from these sources.

Examples:

```bash
python -m ci_agent.cli --cmd CI_compare --entities "Company A" "Company B" --format markdown --urls https://example1.com https://example2.com
python -m ci_agent.cli --cmd CI_matrix --entities "Company A" "Company B" "Company C" --criteria "Evaluation speed" "ATO readiness" "Integration effort" "TCO 3yr"
python -m ci_agent.cli --cmd CI_signals --topic "AI-enabled knowledge management in U.S. federal market"
python -m ci_agent.cli --cmd CI_playbook --entity "Company A" --urls https://example1.com
```

## Streamlit UI

Run locally:

```bash
make run
```

In the UI, select a command, provide entities or topic, choose output format, and run. JSON output will render as structured JSON when valid. Markdown is the default.

## Docker

Build the image:

```bash
make docker-build
```

Run the container (preferred: configure `GOOGLE_API_KEY` in your environment or `.env`):

```bash
# Unix/macOS
export GOOGLE_API_KEY=YOUR_GOOGLE_KEY
make docker-run
# Open http://localhost:8501

# Windows PowerShell
$env:GOOGLE_API_KEY = 'YOUR_GOOGLE_KEY'
make docker-run
```

Note: The repository previously recommended `OPENAI_API_KEY` in some examples; that usage is deprecated. If you need to exercise legacy OpenAI paths, set `OPENAI_API_KEY`, but prefer `GOOGLE_API_KEY` for current development.

## Local container (Podman preferred)

For local development we recommend using Podman where available. The repository provides both Podman-specific make targets and generic `container-*` targets which prefer Podman on Unix-like systems and fall back to Docker if Podman isn't installed.

Build (preferred: podman):

```bash
# prefer Podman when available
make container-build
```

Or explicitly with Podman:

```bash
make podman-build
```

Run the container locally (exposes port 8501):

```bash
export OPENAI_API_KEY=YOUR_KEY
make container-run
# or explicitly: make podman-run
# Open http://localhost:8501
```

Note: GitHub Actions CI in `.github/workflows/ci.yml` continues to use Docker buildx and the docker/* actions for image build/publish. The Makefile keeps `docker-build` and `docker-run` targets for CI and Docker users.

## GitHub Actions CI

The workflow `.github/workflows/ci.yml`:

1. Installs uv and syncs dependencies.
2. Runs ruff lint and format checks.
3. Runs pytest.
4. Builds and pushes a Docker image to GHCR for pushes to main or version tags (v*).

To enable GHCR pushes, ensure `packages: write` permission is available for the workflow and your repository is public or you have access rights.

## Runtime and provider guidance

This project now prefers Google Generative (Gemini) / ADK as the runtime for generation. Key points:

- Primary (recommended) runtime: `google-generativeai` / ADK (Gemini) — the Streamlit UI and adapters will try to use `GOOGLE_API_KEY` and ADK/GenerativeModel APIs when enabled.
- Legacy fallback: OpenAI/agents `Runner` integration is still present in `src/ci_agent/agent.py` for backward compatibility, but it is deprecated. The code attempts to lazily import the OpenAI/agents path only when Google is not requested.

If you're migrating from an OpenAI-based run, set `GOOGLE_API_KEY` and prefer the Google ADK workflows. The adapter will attempt to discover a supported Gemini model via the SDK and pick an appropriate model (for example, `gemini-1.5` family) when `GOOGLE_MODEL` is not set.

## Development Notes

- uv manages a local virtual environment at `.venv` when `UV_PROJECT_ENVIRONMENT=.venv` is set.
- ruff is configured via `.ruff.toml` or pyproject section. Use `make lint` to verify before commits.
- Commit `uv.lock` for reproducible CI builds.

## Troubleshooting

- If `uv sync` fails inside Docker due to network constraints, ensure your environment has access to PyPI or the package index used by `uv`.
- If you see errors about missing `google.generativeai`, install the optional Google SDK into the uv-managed environment:

  ```bash
  UV_PROJECT_ENVIRONMENT=.venv uv pip install google-generativeai
  ```

- If the adapter prints a model-not-found or 404 error, the SDK may be talking to an API version that no longer exposes older models (for example `gemini-1.0`). Set `GOOGLE_MODEL` to a supported model name or allow the adapter to discover a supported model via `list_models()`.
- If you encounter OpenAI 401s or other OpenAI errors unexpectedly, ensure you either:
  - Set `GOOGLE_API_KEY` and enable the Google integration in the Streamlit UI (preferred), or
  - Remove any placeholder `OPENAI_API_KEY` from your environment to avoid accidental initialization of legacy OpenAI clients.

- For JSON output, ensure the requested `format` is `json` and that the model instructions return valid JSON.

## License

Copyright (c) 2025 Michael Nau
